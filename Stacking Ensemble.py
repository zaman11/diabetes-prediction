# -*- coding: utf-8 -*-
"""Copy of Untitled14.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1a-iag7HZzcAGvh4EbPvVGfNUl0MlRNxx
"""

from google.colab import drive
drive.mount('/content/drive')

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# ML libraries for data processing
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.compose import ColumnTransformer
from sklearn.model_selection import train_test_split

data = pd.read_csv('/content/drive/MyDrive/diabetes2.csv')

"""# Exploratory Data Analysis (EDA)¶
Display the first five rows of the DataFrame to understand the variables
"""

data.head()

data.tail()

"""## Explore information about the structure, data types, and memory usage of the DataFrame."""

data.info()

data.shape

data.columns

"""### Create a histogram of the age variable"""

# Set the figure size
plt.figure(figsize=(10, 6))

# Create a histogram using Seaborn
sns.histplot(data['Age'], kde=True)

# Add title and labels
plt.title('Histogram of Age')
plt.xlabel('Age')
plt.ylabel('Number of Patients')

# Show the plot
plt.show()

plt.figure(figsize=(10, 6))
sns.histplot(data['SkinThickness'], kde=True)

plt.title('Histogram of the Skin Thickness')
plt.xlabel('SkinThickness')
plt.ylabel('Number of Patients')

plt.show()

"""### Create a heatmap of the correlation matrix to compute the correlation coefficients between all pairs of variables in the DataFrame"""

# Set the figure size
plt.figure(figsize=(12, 8))

# Create a heatmap using Seaborn
sns.heatmap(data.corr(), annot=True, cmap='coolwarm', fmt='.2f')

# Add title
plt.title('Correlation Matrix')

# Show the plot
plt.show()

"""### check if there are any missing values in the DataFrame"""

missing_values = data.isnull().sum()
print(missing_values)

"""# Data Preparation¶
Handle outliers using the mean. We calculate the lower and upper bounds based on the interquartile range (IQR) and replaces any values outside this range with the mean of the respective column.
Note: We compute for each variable:

Q1: The first quantile (25%)
Q3: The third quantile (75%)
IQR=Q3−Q1
The lowerbound=Q1−1.5∗IQR
The upperbound=Q3+1.5∗IQR
After that, we replace the outliers by lower and upper bounds
"""

for col in data.columns:
    Q1 = data[col].quantile(0.25)
    Q3 = data[col].quantile(0.75)
    iqr = Q3 - Q1
    lower_bound = Q1 - 1.5 * iqr
    upper_bound = Q3 + 1.5 * iqr
    data[col] = np.where((data[col] < lower_bound) | (data[col] > upper_bound), data[col].mean(), data[col])

# Calculate the lower and upper bounds for outliers
Q1 = data.quantile(0.25)
Q3 = data.quantile(0.75)
IQR = Q3 - Q1

lower_bound = Q1 - 1.5 * IQR
upper_bound = Q3 + 1.5 * IQR

# Identify outliers
outliers = ((data < lower_bound) | (data > upper_bound))

# Set the figure size
plt.figure(figsize=(15, 8))

# Create boxplots
sns.boxplot(data=data)

# Add title and labels
plt.title('Boxplots of Variables with Outliers Highlighted')
plt.xlabel('Variables')
plt.ylabel('Values')

# Show the number of outliers for each column above the boxplots
for col in data.columns:
    num_outliers = outliers[col].sum()
    plt.text(data.columns.get_loc(col), upper_bound[col] + 0.1 * (upper_bound.max() - lower_bound.min()),
             f'Outliers: {num_outliers}', ha='center', va='center', color='red')

# Show the plot
plt.show()

"""## Split the de data in to parts or sets; features and target.

Target is the column Outcome
Features are all the columns except the target
"""

X = data.drop('Outcome', axis=1)
y = data['Outcome']

"""show the number of observations for each class (1 and 0) in the 'Outcome' column"""

print(f"Unique values in 'Outcome' column: {y.unique()}")
print(f"Number of unique values in 'Outcome' column: {y.nunique()}")
print(f'Count the number of observations for each class \n: {y.value_counts()}')

"""visualize the distribution of unique values in the 'Outcome' column, which contains binary values (1 and 0)"""

# Plot the distribution
plt.figure(figsize=(8, 6))
sns.countplot(x=y)
plt.title('Distribution of Unique Values in "Outcome" Column')
plt.xlabel('Outcome')
plt.ylabel('Count')
plt.show()

y.value_counts().plot(kind='bar', color=['skyblue', 'lightcoral'])

"""From the statistics describtion of the data (data.discribe()), we can see the columns must be scaled

Normalizing numeric variables with StandardScaler
"""

scaler = StandardScaler()
X = scaler.fit_transform(X)

"""## Show the Normalisation result"""

X_df = pd.DataFrame(X, columns=data.columns[:-1])
X_df.describe()

"""# Modelling¶
In this modelling phase we use:
"""

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

"""#Display the shape of the splited sets: X_train, X_test, y_train, y_test"""

print(f'The shape of training features is: {X_train.shape}')
print(f'The shape of training target is: {y_train.shape}')

print(f'The shape of testing features is: {X_test.shape}')
print(f'The shape of testing target is: {y_test.shape}')

from sklearn import datasets
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score,precision_score, recall_score, f1_score

# Initialize the Random Forest classifier with specific hyperparameters
clf = RandomForestClassifier(n_estimators=2000, max_depth=3, min_samples_split=4, random_state=42)

# Train the classifier on the training set
clf.fit(X_train, y_train)

# Predict the labels of the test set
y_pred = clf.predict(X_test)

# Calculation of accuracy
accuracy = accuracy_score(y_test, y_pred)

# Calculation of precision
precision = precision_score(y_test, y_pred)

# Calculation of recall
recall = recall_score(y_test, y_pred)

# Calculation of F1 score
f1 = f1_score(y_test, y_pred)

# Displaying the results
print("Accuracy: {:.2f}%".format(accuracy * 100))
print("Precision: {:.2f}%".format(precision * 100))
print("Recall: {:.2f}%".format(recall * 100))
print("F1 Score: {:.2f}%".format(f1 * 100))

"""# Stacking Ensemble"""

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import StandardScaler
from scipy.stats import mode

# Load the dataset
df = pd.read_csv('/content/drive/MyDrive/diabetes2.csv')

# Inspect the dataset to understand its structure (optional)
# print(df.head())

# Assuming the last column is the target variable
X = df.iloc[:, :-1].values
y = df.iloc[:, -1].values

# Normalize the features
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)


# Train two Random Forest classifiers
model_1 = RandomForestClassifier(n_estimators=2000, max_depth=3, min_samples_split=4, random_state=43)
model_1.fit(X_train, y_train)

model_2 = RandomForestClassifier(n_estimators=2000, max_depth=3, min_samples_split=4, random_state=43)
model_2.fit(X_train, y_train)

# Predict with both models
predictions_1 = model_1.predict(X_test)
predictions_2 = model_2.predict(X_test)

# Combine the predictions using majority voting
combined_predictions = mode(np.column_stack((predictions_1, predictions_2)), axis=1)[0].flatten()

# Evaluate the model
accuracy = accuracy_score(y_test, combined_predictions)

print("Accuracy:", accuracy)

# Calculation of accuracy
accuracy = accuracy_score(y_test, combined_predictions)

# Calculation of precision
precision = precision_score(y_test, combined_predictions)

# Calculation of recall
recall = recall_score(y_test, combined_predictions)

# Calculation of F1 score
f1 = f1_score(y_test, combined_predictions)

# Displaying the results
print("Accuracy: {:.2f}%".format(accuracy * 100))
print("Precision: {:.2f}%".format(precision * 100))
print("Recall: {:.2f}%".format(recall * 100))
print("F1 Score: {:.2f}%".format(f1 * 100))

import matplotlib.pyplot as plt

# Let's assume these are the accuracies
accuracy_concatenated_ANN = 0.79
accuracy_other_model = 0.71

# Defining labels and values
models = ['Concatenated ANN', 'ANN_Base_Model']
accuracies = [accuracy_concatenated_ANN, accuracy_other_model]

# Creating the bar chart
plt.figure(figsize=(8, 5))
plt.bar(models, accuracies, color=['blue', 'green'])
plt.xlabel('Model')
plt.ylabel('Accuracy')
plt.title('Comparison of Model Accuracies')
plt.ylim(0, 1)  # Assuming accuracy values range from 0 to 1
plt.show()

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier, StackingClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import roc_curve, auc
import matplotlib.pyplot as plt

# Load and preprocess the dataset
df = pd.read_csv('/content/drive/MyDrive/diabetes2.csv')
X = df.drop(columns=[df.columns[-1]])  # Assuming the last column is the target
y = df[df.columns[-1]]

# Normalize the features
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Split the data
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)

# Define and fit the Random Forest model
rf_model = RandomForestClassifier(n_estimators=2000, max_depth=3, min_samples_split=4, random_state=42)
rf_model.fit(X_train, y_train)

# Define and fit the Stacking model
stacking_model = StackingClassifier(
    estimators=[
        ('rf1', RandomForestClassifier(n_estimators=2000, max_depth=3, min_samples_split=4,random_state=42)),
        ('rf2', RandomForestClassifier(n_estimators=7000, max_depth=2, min_samples_split=4,random_state=43))
    ],
    final_estimator=LogisticRegression()
)
stacking_model.fit(X_train, y_train)

# Predict probabilities for the test set
rf_probs = rf_model.predict_proba(X_test)[:, 1]
stacking_probs = stacking_model.predict_proba(X_test)[:, 1]

# Calculate ROC curve points
rf_fpr, rf_tpr, _ = roc_curve(y_test, rf_probs)
stacking_fpr, stacking_tpr, _ = roc_curve(y_test, stacking_probs)

# Plot the ROC curves
plt.figure(figsize=(10, 7))
plt.plot(rf_fpr, rf_tpr, label=f'Random Forest (AUC = {auc(rf_fpr, rf_tpr):.2f})')
plt.plot(stacking_fpr, stacking_tpr, label=f'Stacking Ensemble (AUC = {auc(stacking_fpr, stacking_tpr):.2f})')
plt.plot([0, 1], [0, 1], 'k--')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve Comparison')
plt.legend(loc='lower right')
plt.show()